{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{center}\n",
    "\\begin{huge}\n",
    "MCIS6273 Data Mining (Prof. Maull) / Fall 2023 / HW0\n",
    "\\end{huge}\n",
    "\\end{center}\n",
    "\n",
    "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n",
    "|:---------------:|:--------:|:---------------:|\n",
    "| 20 | Tuesday September 26 @ Midnight | _up to_ 4 hours |\n",
    "\n",
    "\n",
    "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n",
    "\n",
    "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n",
    "\n",
    "## OBJECTIVES\n",
    "* Familiarize yourself with Github and basic git\n",
    "\n",
    "* Familiarize yourself with the JupyterLab environment, Markdown and Python\n",
    "\n",
    "* Explore JupyterHub Linux console integrating what you learned in the prior parts of this homework\n",
    "\n",
    "* Listen to the Talk Python To Me from July 7, 2023: How data scientists use Python\n",
    "\n",
    "* Perfom basic data engineering in Python using Gutenberg.org text of Bertrand Russell's 1912 work _The Problems of Philosophy_\n",
    "\n",
    "* Use structured data to develop basic statistical analyses\n",
    "\n",
    "## WHAT TO TURN IN\n",
    "You are being encouraged to turn the assignment in using the provided\n",
    "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n",
    "`homework/hw0`.   Put all of your files in that directory.  Then zip that directory,\n",
    "rename it with your name as the first part of the filename (e.g. `maull_hw0_files.zip`), then\n",
    "download it to your local machine, then upload the `.zip` to Blackboard.\n",
    "\n",
    "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n",
    "on the basics of using zip in Linux.\n",
    "\n",
    "If you choose not to use the provided notebook, you will still need to turn in a\n",
    "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n",
    "this homework.\n",
    "\n",
    "\n",
    "## ASSIGNMENT TASKS\n",
    "### (0%) Familiarize yourself with Github and basic git \n",
    "\n",
    "[Github (https://github.com)](https://github.com) is the _de facto_ platform for open source software in the world based\n",
    "on the very popular [git (https://git-scm.org)](https://git-scm.org) version control system. Git has a sophisticated set\n",
    "of tools for version control based on the concept of local repositories for fast commits and remote\n",
    "repositories only when collaboration and remote synchronization is necessary.  Github enhances git by providing\n",
    "tools and online hosting of public and private repositories to encourage and promote sharing and collaboration.\n",
    "Github hosts some of the world's most widely used open source software.\n",
    "\n",
    "**If you are already familiar with git and Github, then this part will be very easy!**\n",
    "\n",
    "**&#167; Task:**  **Create a public Github repo named `\"mcis6273-f23-datamining\"` and place a readme.md file in it.**\n",
    "Create your first file called\n",
    "`README.md` at the top level of the repository.  \n",
    "\n",
    "Please put your Zotero username in the file. Aside from that you can put whatever text you like in the file \n",
    "(If you like, use something like [lorem ipsum](https://lipsum.com/)\n",
    "to generate random sentences to place in the file.).\n",
    "Please include the link to **your** Github repository that now includes the minimal `README.md`. \n",
    "You don't have to have anything elaborate in that file or the repo. \n",
    "\n",
    "\n",
    "**&#167; Task:**  Fork the course repository:\n",
    "\n",
    "* [https://github.com/kmsaumcis/mcis6273_f23_datamining/](https://github.com/kmsaumcis/mcis6273_f23_datamining/)\n",
    "\n",
    "\n",
    "\n",
    "### (10%) Familiarize yourself with the JupyterLab environment, Markdown and Python \n",
    "\n",
    "As stated in the course announcement [Jupyter (https://jupyter.org)](https://jupyter.org) is the\n",
    "core platform we will be using in this course and\n",
    "is a popular platform for data scientists around the world.  We have a JupyterLab\n",
    "setup for this course so that we can operate in a cloud-hosted environment, free from\n",
    "some of the resource constraints of running Jupyter on your local machine (though you are free to set\n",
    "it up on your own and seek my advice if you desire).\n",
    "\n",
    "You have been given the information about the  Jupyter environment we have setup for our course, and\n",
    "the underlying Python environment will be using is the [Anaconda (https://anaconda.com)](https://anaconda.com)\n",
    "distribution.  It is not necessary for this assignment, but you are free to look at the multitude\n",
    "of packages installed with Anaconda, though we will not use the majority of them explicitly.\n",
    "\n",
    "As you will soon find out, Notebooks are an incredibly effective way to mix code with narrative\n",
    "and you can create cells that are entirely code or entirely Markdown.  Markdown (MD or `md`) is\n",
    "a highly readable text format that allows for easy documentation of text files, while allowing\n",
    "for HTML-based rendering of the text in a way that is style-independent.\n",
    "\n",
    "We will be using Markdown frequently in this course, and you will learn that there are many different\n",
    "\"flavors\" or Markdown.  We will only be using the basic flavor, but you will benefit from exploring\n",
    "the \"Github flavored\" Markdown, though you will not be responsible for using it in this course -- only the\n",
    "\"basic\" flavor.  Please refer to the original course announcement about Markdown.\n",
    "\n",
    "**&#167; Task:**  **THERE IS NOTHING TO TURN IN FOR THIS PART.** \n",
    "\n",
    "Play with and become familiar with the basic functions of\n",
    "the Lab environment given to you online in the course Blackboard.\n",
    "\n",
    "\n",
    "**&#167; Task:**  **Please _create a markdown document_ called `semester_goals.md` with 3 sentences/fragments that\n",
    "answer the following question:**\n",
    "\n",
    "* **What do you wish to accomplish this semester in Data Mining?**\n",
    "\n",
    "Read the documentation for basic Markdown [here](https://www.markdownguide.org/basic-syntax). \n",
    "Turn in the text `.md` file *not* the processed `.html`.  In whatever you turn in, \n",
    "you must show the use of *ALL* the following:\n",
    "\n",
    "* headings (one level is fine),\n",
    "* bullets,\n",
    "* bold and italics\n",
    "\n",
    "Again, the content of your document needs to address the question above and it should live\n",
    "in the top level directory of your assignment submission.  This part will be graded but no\n",
    "points are awarded for your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (0%) Explore JupyterHub Linux console integrating what you learned in the prior parts of this homework \n",
    "\n",
    "The Linux console in JupyterLab is a great way to perform command-line tasks and is an essential tool\n",
    "for basic scripting that is part of a data scientist's toolkit.  Open a console in the lab environment\n",
    "and familiarize yourself with your files and basic commands using git as indicated below.\n",
    "\n",
    "1. In a new JupyterLab command line console, run the `git clone` command to clone the new\n",
    "  repository you created in the prior part.\n",
    "  You will want to read the documentation on this \n",
    "  command (try here [https://www.git-scm.com/docs/git-clone](https://www.git-scm.com/docs/git-clone) to get a good\n",
    "  start).\n",
    "2. Within the same console, modify your `README.md` file, check it in and push it back to your repository, using\n",
    "  `git push`.  Read the [documentation about `git push`](https://git-scm.com/docs/git-push).\n",
    "3. The commands `wget` and `curl` are useful for grabbing data and files from remote resources off the web.\n",
    "  Read the documentation on each of these commands by typing `man wget` or `man curl` in the terminal.\n",
    "  Make sure you pipe the output to a file or use the proper flags to do so.\n",
    "\n",
    "**&#167; Task:**  **THERE IS NOTHING TO TURN IN FOR THIS PART.**\n",
    "\n",
    "\n",
    "\n",
    "### (30%) Listen to the Talk Python To Me from July 7, 2023: How data scientists use Python \n",
    "\n",
    "Data science is one of the most important and \"hot\" disciplines today\n",
    "and there is a lot going on from data engineering to modeling and\n",
    "analysis. Python is critial to the data scientists \n",
    "toolkit, but they are interesting in their own right.  \n",
    "\n",
    "Why?\n",
    "\n",
    "In this short, interesting and informative podcast, you will learn about\n",
    "the reasons why Python is so hot, and how Python made it to the top \n",
    "of the data science stack.\n",
    "\n",
    "Please listen to this one hour podcast and answer some of the \n",
    "questions below. You can listen to it from one of the two links below:\n",
    "\n",
    "* Talk Python['Podcast'] [Show #433: How data scientists use Python](https://talkpython.fm/episodes/show/422/how-data-scientists-use-python)\n",
    "* direct link to mp3 file [how-data-scientists-use-python.mp3](https://talkpython.fm/episodes/download/422/how-data-scientists-use-python.mp3)\n",
    "\n",
    "**&#167; Task:**  **PLEASE ANSWER THE FOLLOWING QUESTIONS AFTER LISTENING TO THE PODCAST**:\n",
    "\n",
    "  1. List 3 things that you learned from this podcast?\n",
    "  2. What is your reaction to the podcast? Pick at least one point brought up in the interview that you agree with and list your reason why.\n",
    "  3. After listening to the podcast, do you think you are more informed about the importance of Python to Data Science?  How? (Be brief -- one sentence will suffice.)\n",
    "  4. List one _surprising_ fact you learned from listening to this podcast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSWERS\n",
    "1. The three things that i learned from this podcast is\n",
    "    * For Data Science and Machine Learning, python is the most widely used language as it is easy to learn and understand than other programming languages such as java and it also provides many useful libraries like NumPy, Pandas, and Matplotlib.\n",
    "    * Cleaning and preparing data for modeling takes a lot of effort for data scientists. In practice, data is frequently disorganized.\n",
    "    * Also learned about the different tools and softwares, IDE's to code such as PyCharm, jupyter, jupyter Lab, jupyterLite etc.,\n",
    "2. It is very interesting and I agree with one point where the speaker talked about data scientists and engineering teams should work together. The engineering and data science teams are frequently organized in divisions. Their responsibilities and backgrounds might occasionally be very different. But I firmly believe that, atleast, by coordinating their plans, the two teams will be able to learn a great deal about how to solve issues from one another.\n",
    "3. Yes, the podcast highlighted how important Python is for data science. It provides plenty of libraries to work, easy to understand and also flexible.\n",
    "4. One unexpected finding was that a data scientist spends more than 50% of their time cleaning and preparing data. I had anticipated spending more time on analysis and modeling. Also, one more thing which i find surprising to know about a platform in datascience called ponder which is built essentially on top of Moden, which is crucial, Moden.Pandas as PD, it turns all of these Pandas instructions into SQL commands to run within the database where the data resides, which is actually a really fascinating thing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (30%) Perfom basic data engineering in Python using Gutenberg.org text of Bertrand Russell's 1912 work _The Problems of Philosophy_ \n",
    "\n",
    "You learned from the prior part that data science\n",
    "is one of Python's strengths.\n",
    "\n",
    "In this part, you will interact directly with those\n",
    "strengths, but in a way that will allow you to see the \n",
    "challenges that you will face and confront as a real-world\n",
    "data scientist.\n",
    "\n",
    "_Data engineering_ as you have learned from the readings\n",
    "is about transforming data from one form to another so\n",
    "that it can be used in the appropriate analysis \n",
    "contexts.\n",
    "\n",
    "One area of intense work is in transforming unstructured\n",
    "data, like a book or text, into structured data.  More \n",
    "importantly, producing statistical analyses of these \n",
    "unstructured data is often difficult, because one\n",
    "must convert that unstructured data to something that\n",
    "a machine can process algorithmically.\n",
    "\n",
    "In this part of the homework you will take a text \n",
    "from the Project Gutenberg [https://gutenberg.org](https://gutenberg.org)\n",
    "and convert it to something more structured.  In fact,\n",
    "you will convert it to multiple structured forms.\n",
    "\n",
    "For this part we will be working with Betrand Russell's 1912 work _The Problems of Philosphy_\n",
    "which is located at the Project Gutenberg's website [https://gutenberg.org](https://gutenberg.org).\n",
    "The `.txt` file you will want to work with is here:\n",
    "\n",
    "* [https://www.gutenberg.org/cache/epub/5827/pg5827.txt](https://www.gutenberg.org/cache/epub/5827/pg5827.txt)\n",
    "\n",
    "If you are not familiar with Betrand Russell, \n",
    "you may want to be.  He is widely regarded as an \n",
    "important and influential 20th century western logician, mathematician and\n",
    "philosopher who made prolific, deep and crucial contributions to the\n",
    "philosophy of mathematics, logic, set theory, computer science,\n",
    "artificial intelligence, epistemology and metaphysics. \n",
    "\n",
    "Additionally, if you are unfamiliar with Project Gutenberg, you can learn more about it\n",
    "here: [https://gutenberg.org/about/background/](https://gutenberg.org/about/background/). It \n",
    "is an essential repository of many classic books and \n",
    "texts which are now out of copyright, but more importantly it's founder, Michael Hart, \n",
    "invented eBooks\n",
    "in 1971, before probably all of us were born, and certainly before the widespread\n",
    "ubiquity of the public Internet as we know it.  It is a fascinating\n",
    "history that you should know a little about.\n",
    "\n",
    "For our purposes, though, what makes Gutenberg most interesting is that\n",
    "we can directly obtain the `.txt` version of the texts allowing us to \n",
    "use the power of Python to computationally process this unstructured data\n",
    "and convert it to something more useful to our machines and algorithms.\n",
    "\n",
    "Your code must be implemented in Jupyter as a notebook -- you\n",
    "will be required to turn in a `.ipynb` file.\n",
    "\n",
    "**&#167; Task:**  **Use Python to parse and tokenize the text file.**\n",
    "\n",
    "You will produce a `.csv` file which will have\n",
    "all the full words lowercase and\n",
    "with all punctuation removed _unless_ it is part\n",
    "of the word.  For example, if you have a token\n",
    "\"`world.`\", you will drop the ending period,\n",
    "however, if you have a word   \"`can't`\", you will\n",
    "retain the apostrophe \"`'`\".\n",
    "\n",
    "Your output `.csv` file will contain all the \n",
    "words in alphabetical order with their frequency \n",
    "counts.\n",
    "\n",
    "Here is an example of some lines in such a `.csv` file:\n",
    "\n",
    "```\n",
    "...\n",
    "\n",
    "the,112\n",
    "there,62\n",
    "thing,3\n",
    "this,200\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "**NOTE:** Only the words (first column) are sorted, the\n",
    "counts do not need to be sorted.\n",
    "\n",
    "Please name your file `all_words.csv`.\n",
    "\n",
    "\n",
    "**&#167; Task:**  Now that we have all the words, let's go back to the \n",
    "drawing board and **get all _capitalized_ (uppercase) words**.\n",
    "\n",
    "To do this, you will tokenize as before, but you will\n",
    "retain only those words that are capitalized.\n",
    "\n",
    "Also, as before, you will remove punctuation except\n",
    "when it is part of the word, such as an example\n",
    "of a possessive proper noun like \"`Carl's`\".\n",
    "\n",
    "You will also include the frequency counts of these\n",
    "capitalized words in _sorted_ order by word.\n",
    "\n",
    "Please name your file `all_uppercase_words.csv`\n",
    "\n",
    "\n",
    "**&#167; Task:**  **Answer the following questions:**\n",
    "\n",
    "  1. Which were the 5 most frequent words in `all_words.csv` were most frequent?\n",
    "  2. Which were the 5 most frequent words in `all_uppercase_words.csv`.\n",
    "  3. Compare and contrast these top 5.  Explain in 2-3 sentences what you observe about \n",
    "    the similariries and differences.\n",
    "  4. In your own words, what were the most surprising parts of each list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import string\n",
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "url = \"https://www.gutenberg.org/cache/epub/5827/pg5827.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "words = text.split()  # Don't convert to lowercase here\n",
    "processedwords = [word.translate(translator) for word in words]\n",
    "\n",
    "wordcount = Counter(processedwords)\n",
    "\n",
    "with open(\"all_words.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"Word\", \"Frequency\"])\n",
    "    for word, count in sorted(wordcount.items()):\n",
    "        csvwriter.writerow([word, count])\n",
    "\n",
    "pattern = r'\\b[A-Z][A-Za-z\\']*'\n",
    "\n",
    "uwords = re.findall(pattern, text)\n",
    "processedwords = [word.translate(translator) for word in uwords]\n",
    "\n",
    "wordcount = Counter(processedwords)\n",
    "\n",
    "with open(\"all_uppercase_words.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"Word\", \"Frequency\"])\n",
    "    for word, count in sorted(wordcount.items()):\n",
    "        csvwriter.writerow([word, count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most frequent words in all_words.csv are as follows\n",
      "the: 2518\n",
      "of: 1862\n",
      "is: 1322\n",
      "to: 1231\n",
      "and: 983\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# To find Which were the 5 most frequent words in all_words.csv were most frequent?\n",
    "\n",
    "with open(\"all_words.csv\", \"r\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)  # Skip the header row\n",
    "    wordcount = [(word, int(count)) for word, count in csvreader]\n",
    "\n",
    "# Sort words by frequency (in descending order)\n",
    "sorted_wordcount = sorted(wordcount, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the 5 most frequent words\n",
    "frequent5words = sorted_wordcount[:5]\n",
    "\n",
    "print(\"5 most frequent words in all_words.csv are as follows\")\n",
    "for word, count in frequent5words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 most frequent words in all_uppercase_words.csv are as follows\n",
      "The: 191\n",
      "I: 149\n",
      "It: 120\n",
      "But: 119\n",
      "Thus: 113\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# Finding Which were the 5 most frequent words in all_uppercase_words.csv were most frequent?\n",
    "\n",
    "with open(\"all_uppercase_words.csv\", \"r\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)  \n",
    "    upper_wordcount = [(word, int(count)) for word, count in csvreader]\n",
    "\n",
    "sorted_upper_wordcount = sorted(upper_wordcount, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "frequent_5_uppercasewords = sorted_upper_wordcount[:5]\n",
    "\n",
    "print(\"5 most frequent words in all_uppercase_words.csv are as follows\")\n",
    "for word, count in frequent_5_uppercasewords:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Similarities and Differences : \n",
    "**Coming to the similarities :** \n",
    "* We can see that common English terms are present in both datasets  Both datasets place the word \"the\" in the top 5 words, both in lowercase and uppercase. This shows that despite its frequent usage in uppercase, the word \"the\" is present throughout the text <br>.\n",
    "**Coming to \r\n",
    "Differences**:\r",
    "* The capitalization of words is the prior difference. The words are all lowercase in the file all_words.csv, whereas they are all uppercase in the file all_uppercase_words.csv. This change in capitalization frequently denotes various grammatical contexts and functions. For example, \"the\" (lowercase) serves as an article, but \"The\" (uppercase) may be used as the start of a sentence or a title.\n",
    "* Next is the Types of Words. all_words.csv's top 5 words contain frequent words that perform a variety of grammatical tasks, such as articles, prepositions, and verbs (\"is\" and \"to\"). However, the top 5 words in all_uppercase_words.csv are made up of words that are generally capitalized, such as personal pronouns (\"I\") and terms that can be used to emphasize contrast or a point (\"But\" and \"Thus\").\n",
    "* Usage Context: In contrast to all_uppercase_words.csv, words in all_words.csv is used in ordinary language while the words in all_ uppercase _words.csv's might mean anything special in terms of grammar or context. For example, \"I\" is a pronoun used to refer to oneself, and \"But\" is frequently employed to establish a contrast or contradiction in a sentence..\n",
    "s\").\r\n",
    "Usage Context: In contrast to all_uppercase_words.csv, words in all_words.csv is used in ordinary language while the words in all_ uppercase _words.csv's might mean anything special in terms of grammar or context. For example, \"I\" is a pronoun used to refer to oneself, and \"But\" is frequently employed to establish a contrast or contradiction in a sentence.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. In your own words, what were the most surprising parts of each list?\n",
    "**ANS** In 'all_words.csv, thee sheer frequency of basic words like \"the,\" \"of,\" \"is,\" \"to,\" and \"and\" is the most surprising aspect. There are hundreds of instances of these terms throughout the book. It serves as a reminder of how crucial these terms are to the English language's grammar and everyday conversation.\r\n",
    "And for the words in \"all_uppercase_words.csv\": What stands out about this list of the top 5 words is how frequently personal pronouns like \"I\" and words like \"but\" and \"thus\" are used. These terms are frequently used to emphasize points or provide contrast to phrases. Their significance in expressing the author's ideas and arguments in a philosophical book like Bertrand Russell's \"The Problems of Philosophy\" is highlighted by their high ranking. \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (30%) Use structured data to develop basic statistical analyses \n",
    "\n",
    "Now that we have a sense of taking this text and producing\n",
    "some output files that are quite a bit more interesting,\n",
    "we are going to go further into some statistical \n",
    "analyses.\n",
    "\n",
    "Of course, one thing that we are concerned about in \n",
    "unstructured data, are elements that do not add much \n",
    "to our understanding or conversion of that data.\n",
    "\n",
    "One such area in the English language, at least (and most\n",
    "other languages), are words that do not increase the\n",
    "information of the sentence at an _essential_ level.\n",
    "\n",
    "For example, the word `'the'` is not a very useful word\n",
    "when analyzing text, and especially the words that add\n",
    "to the meaning of a sentence.  It is usually the \n",
    "_nouns_ and _verbs_ that get us to the useful parts,\n",
    "and then the _pronouns_, _adjectives_, _adverbs_, etc.\n",
    "Critically, the less common a word is, the more\n",
    "likely that word is important to understanding a text.\n",
    "\n",
    "We are going to delve into a basic and rudimentary \n",
    "statistical analysis of the text.\n",
    "\n",
    "When we are done, we should be able to answer a question\n",
    "like _How likely is it to see a sentence with the\n",
    "words `car`, `plant`, `simple`?_  We will also continue\n",
    "some basic data engineering along the way.\n",
    "\n",
    "**&#167; Task:**  **Remove the stopwords from your `all_words.csv` and put the \n",
    "remaining non-stopwords in a file `all_ns_words.csv`. Please \n",
    "retain the frequency column as before.**\n",
    "\n",
    "A good list of stopwords to start with can be found here:\n",
    "\n",
    "* [https://raw.githubusercontent.com/stopwords-iso/stopwords-en/master/stopwords-en.txt](https://raw.githubusercontent.com/stopwords-iso/stopwords-en/master/stopwords-en.txt)\n",
    "\n",
    "Furthermore, you can learn what a _stopword_ is from the excellent\n",
    "text Christopher D. Manning, Prabhakar Raghavan and \n",
    "Hinrich Schütze, Introduction to Information Retrieval, Cambridge University Press. 2008. \n",
    "[https://nlp.stanford.edu/IR-book/](https://nlp.stanford.edu/IR-book/).  :\n",
    "\n",
    "* here is primary source information on stopwords [https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html)\n",
    "\n",
    "\n",
    "**&#167; Task:**  **Add a new column to your `all_ns_words.csv` that \n",
    "  contains the probability of that word.**\n",
    "\n",
    "To do this, use the denomator of the sum of stopwords\n",
    "**not** all words.  Alternatively, do not include\n",
    "stopword counts in your sum.\n",
    "\n",
    "Thus, $W$ are all words and if $w$ is a non-stopword, $w \\in W$, let $C_{w}$ be the\n",
    "frequency (count) of word $w$.  Thus, \n",
    "$$ \\Pr(w \\in W) = \\frac{C_w}{\\sum_{w' \\in W} C_{w'}}.$$\n",
    "\n",
    "Concretely, if \"`righteous`\" appears 200 times,\n",
    "and the sum of frequencies of all non-stopwords\n",
    "is 10000, then $\\Pr(w=righteous) = \\frac{200}{10000} = 0.02$.\n",
    "\n",
    "Your new file will look something like:\n",
    "\n",
    "```\n",
    "...\n",
    "friend, 112, .003\n",
    "fruit, 67, .00014\n",
    "grand, 88, .01763\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**&#167; Task:**  **Answer the following questions using your analysis and results from the text:**\n",
    "\n",
    "1. How many unique non-stop words are in the text?\n",
    "2. Which is the least probable word? (if there is a tie, please state the tie words)\n",
    "3. What observation can you make about the probabilities?\n",
    "4. Which sentence is more likely:\n",
    "\n",
    "    a. _If a belief is true, it can be deduced it is universal._\n",
    "    b. _Criticism of knowledge is counter to scientific results._\n",
    "    <br/>\n",
    "\n",
    "    You will use the sum of the probabilities of\n",
    "    each non-stop word to answer the question. You will need to \n",
    "    give numeric rationale for your answer. Show your work in Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import requests\n",
    "\n",
    "stopwords_url = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-en/master/stopwords-en.txt\"\n",
    "response = requests.get(stopwords_url)\n",
    "stopwords = set(response.text.splitlines())\n",
    "\n",
    "\n",
    "word_counts = Counter()\n",
    "with open(\"all_words.csv\", \"r\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)  \n",
    "    for word, count in csvreader:\n",
    "        word_counts[word] = int(count)\n",
    "\n",
    "total_nsword_frequency = 0\n",
    "nsword_counts = Counter()\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if word.lower() not in stopwords:  \n",
    "        nsword_counts[word] = count\n",
    "        total_nsword_frequency += count\n",
    "\n",
    "with open(\"all_ns_words.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"Word\", \"Frequency\", \"Probability\"])\n",
    "    for word, count in sorted(nsword_counts.items()):\n",
    "        probability = int(count) / total_nsword_frequency\n",
    "        csvwriter.writerow([word, count, probability])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique non-stop words are : 3123\n"
     ]
    }
   ],
   "source": [
    "#Finding out number of unique non-stop words\n",
    "\n",
    "nswords = set()\n",
    "\n",
    "with open(\"all_ns_words.csv\", \"r\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader) \n",
    "    for row in csvreader:\n",
    "        word = row[0]\n",
    "        nswords.add(word)\n",
    "        \n",
    "uniquens_wordcount = len(nswords)\n",
    "\n",
    "print(f\"Number of unique non-stop words are : {uniquens_wordcount}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Probability: 7.450454477723141e-05\n",
      "Least Probable Word(s):\n",
      "1500\n",
      "15961650\n",
      "16461716\n",
      "16851753\n",
      "171176\n",
      "17241804\n",
      "17701831\n",
      "1912\n",
      "1A\n",
      "1B\n",
      "1D\n",
      "1E2\n",
      "1E3\n",
      "1E4\n",
      "1E5\n",
      "1E6\n",
      "1F\n",
      "1F1\n",
      "1F2\n",
      "1F4\n",
      "1F5\n",
      "1F6\n",
      "20\n",
      "2001\n",
      "2004\n",
      "2019\n",
      "30\n",
      "50\n",
      "5000\n",
      "501c3\n",
      "5827\n",
      "5961887\n",
      "60\n",
      "646221541\n",
      "801\n",
      "809\n",
      "84116\n",
      "ACQUAINTANCE\n",
      "ACTUAL\n",
      "AGREEMENT\n",
      "APPEARANCE\n",
      "Acquaintance\n",
      "Additional\n",
      "Atheists\n",
      "Author\n",
      "Awareness\n",
      "BIBLIOGRAPHICAL\n",
      "Bannerman\n",
      "Bismarcks\n",
      "Books\n",
      "Bradley\n",
      "British\n",
      "Broadly\n",
      "CONSEQUENTIAL\n",
      "CONTRACT\n",
      "Campbell\n",
      "Cantor\n",
      "City\n",
      "Cogito\n",
      "Compliance\n",
      "Considered\n",
      "Contact\n",
      "Continental\n",
      "Contributions\n",
      "Copyright\n",
      "Creating\n",
      "DAMAGE\n",
      "DESCRIPTION\n",
      "DIRECT\n",
      "DISCLAIMER\n",
      "DISTRIBUTE\n",
      "DISTRIBUTOR\n",
      "DONATIONS\n",
      "December\n",
      "Defect\n",
      "Degrees\n",
      "Derivative\n",
      "Domestic\n",
      "EIN\n",
      "ERROR\n",
      "EXISTENCE\n",
      "EXPRESS\n",
      "Earth\n",
      "East\n",
      "Email\n",
      "England\n",
      "English\n",
      "Enquiry\n",
      "Ethics\n",
      "Euclids\n",
      "Europe\n",
      "FALSEHOOD\n",
      "FITNESS\n",
      "FOUNDATION\n",
      "Food\n",
      "Future\n",
      "GUTENBERG™\n",
      "Georg\n",
      "George\n",
      "Gilbert\n",
      "Gordon\n",
      "Granted\n",
      "Greeks\n",
      "Gutenbergs\n",
      "Gutenberg™’s\n",
      "Hart\n",
      "Hegels\n",
      "Henry\n",
      "Human\n",
      "Humemaintained\n",
      "Humes\n",
      "IDEALISM\n",
      "III\n",
      "IMPLIED\n",
      "INCIDENTAL\n",
      "INCLUDING\n",
      "INDEMNITY\n",
      "INDIRECT\n",
      "INDUCTION\n",
      "INTUITIVE\n",
      "IRS\n",
      "Idealists\n",
      "Ides\n",
      "Immanuel\n",
      "Instances\n",
      "Internal\n",
      "International\n",
      "Introduction\n",
      "Judgements\n",
      "Judging\n",
      "June\n",
      "Kantian\n",
      "Keener\n",
      "Keynes\n",
      "Kings\n",
      "Königsberg\n",
      "LIABILITY\n",
      "LIABLE\n",
      "LIMITS\n",
      "Lake\n",
      "Language\n",
      "Latin\n",
      "Laws\n",
      "Leaving\n",
      "Leibnizmaintained\n",
      "Library\n",
      "Light\n",
      "Locke\n",
      "MERCHANTABILITY\n",
      "March\n",
      "Mathematics\n",
      "Meditations\n",
      "Memories\n",
      "Metaphysic\n",
      "Michael\n",
      "Mission\n",
      "Mississippi\n",
      "Monadology\n",
      "Moore\n",
      "Murray\n",
      "NATURE\n",
      "NEGLIGENCE\n",
      "NOTE\n",
      "NOTICE\n",
      "Neglecting\n",
      "Newtons\n",
      "North\n",
      "OPINION\n",
      "OWNER\n",
      "Opposition\n",
      "PARAGRAPH\n",
      "PGLAF\n",
      "PHILOSOPHICAL\n",
      "POSSIBILITY\n",
      "PREFACE\n",
      "PRINCIPLES\n",
      "PRIORI\n",
      "PROBABLE\n",
      "PUNITIVE\n",
      "PURPOSE\n",
      "Philosophical\n",
      "Principles\n",
      "Produced\n",
      "Prolegomena\n",
      "Pronouns\n",
      "Prussia\n",
      "READ\n",
      "REALITY\n",
      "REFUND\n",
      "REMEDIES\n",
      "REPLACEMENT\n",
      "Rationalists\n",
      "Redistributing\n",
      "Redistribution\n",
      "Reflection\n",
      "Refund”\n",
      "Release\n",
      "Replacement\n",
      "Republic\n",
      "Returning\n",
      "Revenue\n",
      "Revolution\n",
      "Roman\n",
      "SEND\n",
      "STRICT\n",
      "Salt\n",
      "Sceptics\n",
      "Sections\n",
      "Selfacquaintedwithsensedatum\n",
      "Selfassertion\n",
      "Selfevidence\n",
      "Sensedata\n",
      "Service\n",
      "Sir\n",
      "Space\n",
      "Speaking\n",
      "Special\n",
      "Starting\n",
      "Struldbugs\n",
      "Swift\n",
      "Systemsimilarly\n",
      "TRADEMARK\n",
      "TRUTH\n",
      "Times\n",
      "Title\n",
      "Truth\n",
      "Truths\n",
      "UT\n",
      "Understanding\n",
      "Uneducated\n",
      "Universals\n",
      "Universe\n",
      "University\n",
      "Unsupported\n",
      "Updated\n",
      "VIII\n",
      "Volunteers\n",
      "War\n",
      "Waterloo\n",
      "West\n",
      "Whitehead\n",
      "XII\n",
      "XIII\n",
      "XIV\n",
      "XV\n",
      "York\n",
      "abide\n",
      "abstain\n",
      "abstracted\n",
      "abstractions\n",
      "abstractly\n",
      "absurdities\n",
      "acceptance\n",
      "accepts\n",
      "accessed\n",
      "accessible\n",
      "accident\n",
      "accidental\n",
      "accidents\n",
      "accompanied\n",
      "accord\n",
      "accounting\n",
      "accurate\n",
      "accusative\n",
      "achieve\n",
      "achieves\n",
      "acquaintedusually\n",
      "acquiesce\n",
      "acquiescence\n",
      "acquisition\n",
      "activity\n",
      "acute\n",
      "adapts\n",
      "adding\n",
      "address\n",
      "addresses\n",
      "adduced\n",
      "adequacy\n",
      "adequately\n",
      "admirable\n",
      "admittedthat\n",
      "admitthough\n",
      "admitting\n",
      "admixture\n",
      "advances\n",
      "adversaries\n",
      "advocate\n",
      "advocates\n",
      "advocating\n",
      "aesthetic\n",
      "aether\n",
      "affairs\n",
      "affections\n",
      "affirmative\n",
      "afforded\n",
      "agent\n",
      "agreeably\n",
      "agreedthe\n",
      "aim\n",
      "aimed\n",
      "akin\n",
      "alien\n",
      "allembracing\n",
      "allimportant\n",
      "allowed\n",
      "allowing\n",
      "allround\n",
      "alteration\n",
      "altered\n",
      "alternate\n",
      "alternatives\n",
      "alters\n",
      "ambitious\n",
      "amend\n",
      "amply\n",
      "analogous\n",
      "analyse\n",
      "analyses\n",
      "anatomist\n",
      "animal\n",
      "announcement\n",
      "anticipate\n",
      "anticipating\n",
      "anticipation\n",
      "anybodys\n",
      "appearances\n",
      "appearing\n",
      "appetite\n",
      "application\n",
      "applied\n",
      "apportions\n",
      "apprehendedmust\n",
      "apprehends\n",
      "approaches\n",
      "approaching\n",
      "arduous\n",
      "argued\n",
      "arguedcorrectly\n",
      "argues\n",
      "arguing\n",
      "arose\n",
      "arrange\n",
      "array\n",
      "arrived\n",
      "arriving\n",
      "arrogant\n",
      "artificial\n",
      "ascertained\n",
      "assassinated\n",
      "assented\n",
      "assigns\n",
      "assimilate\n",
      "assist\n",
      "assumptions\n",
      "assurance\n",
      "assure\n",
      "assured\n",
      "astray\n",
      "ate\n",
      "atoms\n",
      "attached\n",
      "attack\n",
      "attain\n",
      "attainable\n",
      "attainedmany\n",
      "attested\n",
      "attitude\n",
      "attributing\n",
      "avoided\n",
      "avoiding\n",
      "awaresay\n",
      "away—you\n",
      "babies\n",
      "badit\n",
      "baldness\n",
      "banging\n",
      "bar\n",
      "barrier\n",
      "beat\n",
      "bed\n",
      "beg\n",
      "begging\n",
      "beginner\n",
      "begs\n",
      "begun\n",
      "behave\n",
      "behaviour\n",
      "beingas\n",
      "beis\n",
      "beleagured\n",
      "beliefsfor\n",
      "beliefssuch\n",
      "believesto\n",
      "bell\n",
      "besomething\n",
      "bewildering\n",
      "bid\n",
      "bigger\n",
      "binary\n",
      "binds\n",
      "blank\n",
      "bluegreen\n",
      "bolder\n",
      "bone\n",
      "bored\n",
      "borne\n",
      "bounds\n",
      "brick\n",
      "briefest\n",
      "brighter\n",
      "brightness\n",
      "broken\n",
      "brotherhood\n",
      "build\n",
      "builder\n",
      "buildings\n",
      "calculate\n",
      "calculated\n",
      "calm\n",
      "campsfriends\n",
      "candid\n",
      "card\n",
      "careful\n",
      "carelessly\n",
      "carry\n",
      "catalogue\n",
      "catalogued\n",
      "catching\n",
      "categories\n",
      "centuries\n",
      "century\n",
      "chance\n",
      "changeable\n",
      "changed\n",
      "charitable\n",
      "charities\n",
      "checks\n",
      "child\n",
      "chimaera\n",
      "choice\n",
      "chosen\n",
      "citizens\n",
      "citizenship\n",
      "city\n",
      "clash\n",
      "clashes\n",
      "clean\n",
      "clock\n",
      "closed\n",
      "closer\n",
      "closes\n",
      "clouds\n",
      "coalesce\n",
      "codes\n",
      "cohere\n",
      "coin\n",
      "coins\n",
      "collective\n",
      "colony\n",
      "colourblind\n",
      "combination\n",
      "combine\n",
      "coming\n",
      "commercial\n",
      "commit\n",
      "communicate\n",
      "community\n",
      "comparative\n",
      "compare\n",
      "compared\n",
      "comparing\n",
      "competent\n",
      "compilation\n",
      "complement\n",
      "completed\n",
      "compressed\n",
      "conceivable\n",
      "conceivably\n",
      "conceiving\n",
      "concentrate\n",
      "concluded\n",
      "concourse\n",
      "condemns\n",
      "conduct\n",
      "confess\n",
      "confine\n",
      "confining\n",
      "confirmation\n",
      "confirmed\n",
      "confirms\n",
      "conflict\n",
      "conformity\n",
      "confused\n",
      "confusing\n",
      "confusions\n",
      "confute\n",
      "conjecture\n",
      "connaître\n",
      "connecting\n",
      "connects\n",
      "consent\n",
      "consequences\n",
      "consisted\n",
      "constituting\n",
      "construct\n",
      "constructed\n",
      "constructing\n",
      "constructions\n",
      "constructive\n",
      "contemplated\n",
      "contemplating\n",
      "contemplative\n",
      "contemptuously\n",
      "contended\n",
      "contention\n",
      "contentions\n",
      "continued\n",
      "continuing\n",
      "continuous\n",
      "continuously\n",
      "contradict\n",
      "contradictory\n",
      "contrast\n",
      "contributed\n",
      "contribution\n",
      "contributions\n",
      "convenient\n",
      "converged\n",
      "conversation\n",
      "convert\n",
      "convincing\n",
      "cool\n",
      "cooperation\n",
      "corporation\n",
      "correctly\n",
      "correlative\n",
      "corresponded\n",
      "corrupt\n",
      "counterparts\n",
      "countless\n",
      "countries\n",
      "cranny\n",
      "creates\n",
      "creation\n",
      "criticisms\n",
      "criticized\n",
      "crudely\n",
      "current\n",
      "custom\n",
      "customary\n",
      "cutting\n",
      "damage\n",
      "damaged\n",
      "danger\n",
      "dataif\n",
      "dates\n",
      "debate\n",
      "debated\n",
      "deceitful\n",
      "deceive\n",
      "deceptive\n",
      "decides\n",
      "deciding\n",
      "decision\n",
      "declared\n",
      "deducing\n",
      "deductible\n",
      "deeds\n",
      "deeply\n",
      "defeated\n",
      "defensible\n",
      "defined\n",
      "definiteness\n",
      "definitions\n",
      "deletions\n",
      "deliberate\n",
      "delightful\n",
      "delusion\n",
      "demanding\n",
      "demonstrably\n",
      "demonstrative\n",
      "demonstratively\n",
      "denies\n",
      "dentist\n",
      "dependence\n",
      "depending\n",
      "descend\n",
      "describes\n",
      "describing\n",
      "descriptive\n",
      "desertit\n",
      "deserts\n",
      "deserves\n",
      "deserving\n",
      "designate\n",
      "desirability\n",
      "desirable\n",
      "desiring\n",
      "desirous\n",
      "destroyed\n",
      "destroys\n",
      "destructive\n",
      "detach\n",
      "determines\n",
      "development\n",
      "developments\n",
      "diary\n",
      "dictionary\n",
      "die\n",
      "differentsomething\n",
      "differingsome\n",
      "diminish\n",
      "diminished\n",
      "diminishes\n",
      "dined\n",
      "dinnertable\n",
      "directions\n",
      "directs\n",
      "disappear\n",
      "disappoint\n",
      "disappointing\n",
      "disclaim\n",
      "disclaimers\n",
      "discontinue\n",
      "discuss\n",
      "disease\n",
      "disengaged\n",
      "disk\n",
      "dismiss\n",
      "dispassionately\n",
      "display\n",
      "displayed\n",
      "disputable\n",
      "disputants\n",
      "dissociated\n",
      "distinctly\n",
      "distinguishes\n",
      "distort\n",
      "distorts\n",
      "diverge\n",
      "diversity\n",
      "divest\n",
      "divide\n",
      "divided\n",
      "divisibilityphilosophers\n",
      "dogmas\n",
      "dogmatic\n",
      "dogmatism\n",
      "domestic\n",
      "dominion\n",
      "donation\n",
      "donors\n",
      "doubtless\n",
      "downloading\n",
      "drawn\n",
      "dreamsthat\n",
      "dreamtable\n",
      "dried\n",
      "drifted\n",
      "drive\n",
      "drives\n",
      "duly\n",
      "easiest\n",
      "eclipse\n",
      "edition\n",
      "educated\n",
      "educational\n",
      "effected\n",
      "elapse\n",
      "elapsed\n",
      "elect\n",
      "elected\n",
      "electric\n",
      "elementary\n",
      "elements\n",
      "elsesomething\n",
      "elucidation\n",
      "embark\n",
      "emerged\n",
      "emerges\n",
      "emitted\n",
      "emitting\n",
      "emphasized\n",
      "emphatically\n",
      "empiricistswho\n",
      "employee\n",
      "employees\n",
      "employs\n",
      "engagement\n",
      "engendered\n",
      "enlarged\n",
      "enlarges\n",
      "enormously\n",
      "enrich\n",
      "ensuring\n",
      "entails\n",
      "entangled\n",
      "enter\n",
      "entertaining\n",
      "enumerated\n",
      "enumeration\n",
      "enunciated\n",
      "equal\n",
      "equivocation\n",
      "ergo\n",
      "esse\n",
      "estimated\n",
      "etcis\n",
      "etcmay\n",
      "etcwhich\n",
      "eternal\n",
      "eternally\n",
      "everyday\n",
      "exact\n",
      "examines\n",
      "exampleraises\n",
      "exceedingly\n",
      "excluding\n",
      "exclusion\n",
      "exemplify\n",
      "existent\n",
      "expend\n",
      "expense\n",
      "experienceas\n",
      "experiencenot\n",
      "explicitly\n",
      "explored\n",
      "exploring\n",
      "exponents\n",
      "exporting\n",
      "expressions\n",
      "extend\n",
      "extends\n",
      "extensive\n",
      "extrinsic\n",
      "fabric\n",
      "faceit\n",
      "facility\n",
      "factsinfinite\n",
      "faculty\n",
      "failing\n",
      "fainter\n",
      "faintness\n",
      "fallacies\n",
      "fallaciouswhich\n",
      "fallacy\n",
      "fallible\n",
      "falls\n",
      "falsified\n",
      "family\n",
      "fancy\n",
      "fast\n",
      "fatal\n",
      "favouritism\n",
      "fear\n",
      "features\n",
      "fed\n",
      "feeds\n",
      "fetters\n",
      "feverish\n",
      "file\n",
      "files\n",
      "financial\n",
      "fine\n",
      "fixed\n",
      "flash\n",
      "foes\n",
      "foolish\n",
      "football\n",
      "force\n",
      "forces\n",
      "forget\n",
      "forgetting\n",
      "forgo\n",
      "forgotten\n",
      "forks\n",
      "formal\n",
      "formally\n",
      "formats\n",
      "fortress\n",
      "fortuitous\n",
      "fortune\n",
      "forwards\n",
      "fostered\n",
      "fourth\n",
      "fragment\n",
      "fragments\n",
      "framework\n",
      "friend\n",
      "frightened\n",
      "fulfilment\n",
      "fulfils\n",
      "gain\n",
      "garrison\n",
      "generality\n",
      "genuinelyempirical\n",
      "geography\n",
      "geology\n",
      "ghoststories\n",
      "glance\n",
      "glasses\n",
      "globe\n",
      "goals\n",
      "goodwill\n",
      "gradations\n",
      "grain\n",
      "grapple\n",
      "grasp\n",
      "gratefully\n",
      "gratuitous\n",
      "gravely\n",
      "greens\n",
      "greenyblue\n",
      "groundless\n",
      "grow\n",
      "growing\n",
      "guarded\n",
      "guide\n",
      "habits\n",
      "habitual\n",
      "habitually\n",
      "hairsplitting\n",
      "halves\n",
      "handbooks\n",
      "happiness\n",
      "hardnesses\n",
      "harm\n",
      "harmless\n",
      "harmony\n",
      "hates\n",
      "hatred\n",
      "hatreds\n",
      "heartbeats\n",
      "heaven\n",
      "heavens\n",
      "helpful\n",
      "heretofore\n",
      "hesitatingly\n",
      "hides\n",
      "hills\n",
      "hinder\n",
      "historian\n",
      "historic\n",
      "historically\n",
      "honour\n",
      "hoofs\n",
      "hoped\n",
      "hopeless\n",
      "horrors\n",
      "host\n",
      "hot\n",
      "howeverwhich\n",
      "hundreds\n",
      "hypertext\n",
      "ideasie\n",
      "identification\n",
      "identity\n",
      "ignorance\n",
      "ignorant\n",
      "illumination\n",
      "illusoriness\n",
      "illusory\n",
      "illustrated\n",
      "illustrations\n",
      "immutable\n",
      "impaired\n",
      "impairs\n",
      "impartial\n",
      "impartially\n",
      "impenetrable\n",
      "impersonal\n",
      "impose\n",
      "impression\n",
      "imprisoned\n",
      "inaccurate\n",
      "inclination\n",
      "includes\n",
      "incompatible\n",
      "inconsistencies\n",
      "inconsistency\n",
      "increase\n",
      "increasing\n",
      "incredulous\n",
      "indefinitely\n",
      "indemnify\n",
      "independence\n",
      "indestructible\n",
      "indicating\n",
      "inevitable\n",
      "inexplicable\n",
      "infallibility\n",
      "infancy\n",
      "infected\n",
      "inferring\n",
      "infinitesimal\n",
      "infinitum\n",
      "inflected\n",
      "inflections\n",
      "influence\n",
      "infringed\n",
      "infringement\n",
      "inhabitants\n",
      "inhabited\n",
      "inherent\n",
      "innocent\n",
      "inoperative\n",
      "inquire\n",
      "inquired\n",
      "insistent\n",
      "insoluble\n",
      "inspiration\n",
      "instants\n",
      "instincts\n",
      "instrument\n",
      "insubstantial\n",
      "intelligent\n",
      "intend\n",
      "intended\n",
      "intently\n",
      "interact\n",
      "interferes\n",
      "intermediary\n",
      "internal\n",
      "interpret\n",
      "interpreted\n",
      "interrelation\n",
      "interrupted\n",
      "introduce\n",
      "intuitively\n",
      "invalidity\n",
      "invented\n",
      "inventing\n",
      "inventions\n",
      "investigations\n",
      "invites\n",
      "involvedat\n",
      "involvedin\n",
      "irrefutable\n",
      "isolation\n",
      "itI\n",
      "itself1\n",
      "ittheoretically\n",
      "jealousy\n",
      "joint\n",
      "justly\n",
      "kennen\n",
      "killed\n",
      "knits\n",
      "knives\n",
      "knowable\n",
      "knowledgefar\n",
      "knowledgeknowledge\n",
      "lapse\n",
      "larger\n",
      "launched\n",
      "lay\n",
      "learnt\n",
      "leaving\n",
      "legally\n",
      "legitimately\n",
      "lessfrom\n",
      "level\n",
      "liberating\n",
      "liberation\n",
      "liberator\n",
      "liberty\n",
      "library\n",
      "licensed\n",
      "lies\n",
      "lifelong\n",
      "lifewhich\n",
      "lightwaves\n",
      "limitations\n",
      "limiting\n",
      "linked\n",
      "lips\n",
      "live\n",
      "lived\n",
      "locations\n",
      "logicallyso\n",
      "logician\n",
      "longestlived\n",
      "longlived\n",
      "looked\n",
      "loose\n",
      "loosen\n",
      "lot\n",
      "loud\n",
      "lowest\n",
      "luminously\n",
      "lying\n",
      "machinereadable\n",
      "magnifies\n",
      "maintain\n",
      "maintaining\n",
      "majority\n",
      "manager\n",
      "manmade\n",
      "manyprofess\n",
      "marching\n",
      "marriage\n",
      "match\n",
      "maximum\n",
      "meanings\n",
      "melt\n",
      "memories\n",
      "mens\n",
      "mention\n",
      "mercilessly\n",
      "merest\n",
      "merges\n",
      "merits\n",
      "metaphorically\n",
      "middle\n",
      "middleaged\n",
      "midst\n",
      "miles\n",
      "mindnot\n",
      "mineralogist\n",
      "minor\n",
      "miracle\n",
      "misery\n",
      "misleadingness\n",
      "mistake\n",
      "mistakes\n",
      "misunderstanding\n",
      "mitigate\n",
      "mode\n",
      "modification\n",
      "modifications\n",
      "modify\n",
      "momentary\n",
      "monad\n",
      "monadism\n",
      "monism\n",
      "month\n",
      "moved\n",
      "movements\n",
      "multiplication\n",
      "multiplicity\n",
      "musical\n",
      "mutually\n",
      "mystic\n",
      "mystical\n",
      "mysticism\n",
      "nation\n",
      "native\n",
      "nearest\n",
      "nearness\n",
      "negligible\n",
      "network\n",
      "newness\n",
      "news\n",
      "newsletter\n",
      "newspapers\n",
      "ninetythree\n",
      "noises\n",
      "nominative\n",
      "nonexistence\n",
      "nonlogical\n",
      "nonprofit\n",
      "nonproprietary\n",
      "nook\n",
      "noteworthy\n",
      "noticing\n",
      "notifies\n",
      "notions\n",
      "nouns\n",
      "novelist\n",
      "nowadays\n",
      "nowhen\n",
      "numerous\n",
      "objectin\n",
      "objectionable\n",
      "objective\n",
      "objectsit\n",
      "oblivious\n",
      "obscure\n",
      "observe\n",
      "observing\n",
      "obsolete\n",
      "obstacle\n",
      "obstacles\n",
      "obstinate\n",
      "obtuse\n",
      "obviousness\n",
      "obviousnessthe\n",
      "occupant\n",
      "occupying\n",
      "odd\n",
      "office\n",
      "oftener\n",
      "omission\n",
      "oneself\n",
      "one—the\n",
      "opaque\n",
      "operated\n",
      "operative\n",
      "opportunities\n",
      "opportunity\n",
      "opposites\n",
      "orator\n",
      "orderly\n",
      "ordnance\n",
      "organized\n",
      "organizing\n",
      "organs\n",
      "origin\n",
      "originally\n",
      "originator\n",
      "outcome\n",
      "outdated\n",
      "outlines\n",
      "outward\n",
      "oval\n",
      "owed\n",
      "painfully\n",
      "palpable\n",
      "papers\n",
      "paperwork\n",
      "paradoxes\n",
      "paradoxical\n",
      "partially\n",
      "partlyand\n",
      "party\n",
      "passage\n",
      "passes\n",
      "pastnor\n",
      "pastnot\n",
      "pausing\n",
      "pay\n",
      "peace\n",
      "peculiar\n",
      "peculiarly\n",
      "percipi\n",
      "perfection\n",
      "performances\n",
      "periodic\n",
      "permanence\n",
      "perpetual\n",
      "persons\n",
      "perspective\n",
      "persuaded\n",
      "persuading\n",
      "perturbed\n",
      "phantasmagoria\n",
      "philosophersor\n",
      "philosophersthat\n",
      "philosophize\n",
      "philosophyfor\n",
      "philosophythe\n",
      "physics\n",
      "physiological\n",
      "physiology\n",
      "pink\n",
      "placesLondon\n",
      "placing\n",
      "plane\n",
      "planet\n",
      "plausibility\n",
      "playing\n",
      "poisonous\n",
      "positively\n",
      "possess\n",
      "possessed\n",
      "possession\n",
      "poverty\n",
      "powerlessness\n",
      "powers\n",
      "practice\n",
      "practised\n",
      "precisely\n",
      "preeminently\n",
      "preferable\n",
      "preparing\n",
      "prescribe\n",
      "presence\n",
      "preservation\n",
      "pressing\n",
      "pressure\n",
      "pressures\n",
      "presumption\n",
      "presupposed\n",
      "pretty\n",
      "prevent\n",
      "primitive\n",
      "principlesperhaps\n",
      "proceeded\n",
      "proceeds\n",
      "processes\n",
      "processing\n",
      "producing\n",
      "production\n",
      "products\n",
      "profitable\n",
      "profited\n",
      "profits\n",
      "profitthe\n",
      "profoundest\n",
      "progress\n",
      "progressively\n",
      "prohibition\n",
      "prolonged\n",
      "promote\n",
      "promotion\n",
      "pronounce\n",
      "pronouns\n",
      "proofread\n",
      "proposed\n",
      "proprietary\n",
      "provision\n",
      "provisionally\n",
      "provisions\n",
      "prudent\n",
      "psychologically\n",
      "psychology\n",
      "pursue\n",
      "pushed\n",
      "puzzling\n",
      "questionsand\n",
      "quibbling\n",
      "range\n",
      "ranging\n",
      "rapping\n",
      "rationalist\n",
      "rationalistswho\n",
      "rationality\n",
      "readable\n",
      "readers\n",
      "realization\n",
      "realized\n",
      "realor\n",
      "reappear\n",
      "reasonsin\n",
      "receiving\n",
      "recognizes\n",
      "recombines\n",
      "reconcile\n",
      "reconstructed\n",
      "recorded\n",
      "redistribute\n",
      "redistributing\n",
      "redistribution\n",
      "reduce\n",
      "reducible\n",
      "refined\n",
      "reflecting\n",
      "refutable\n",
      "regress\n",
      "regulating\n",
      "rejection\n",
      "relate\n",
      "relational\n",
      "relationin\n",
      "reliable\n",
      "religion\n",
      "remarkably\n",
      "remarks\n",
      "remote\n",
      "remoter\n",
      "removal\n",
      "removes\n",
      "renamed\n",
      "renounce\n",
      "repeat\n",
      "repeatedly\n",
      "repetition\n",
      "replaced\n",
      "reported\n",
      "reports\n",
      "represent\n",
      "representations\n",
      "representative\n",
      "representing\n",
      "request\n",
      "resemblances\n",
      "residue\n",
      "restate\n",
      "resting\n",
      "restricted\n",
      "retain\n",
      "retained\n",
      "retort\n",
      "returns\n",
      "revealed\n",
      "reversed\n",
      "revert\n",
      "review\n",
      "rigid\n",
      "rival\n",
      "rob\n",
      "robbing\n",
      "roof\n",
      "rooted\n",
      "rotate\n",
      "rotating\n",
      "roundabout\n",
      "rounded\n",
      "rouse\n",
      "roused\n",
      "royalty\n",
      "runs\n",
      "samples\n",
      "satisfaction\n",
      "satisfying\n",
      "save\n",
      "savoir\n",
      "scaffold\n",
      "sceptic\n",
      "sceptical\n",
      "schoolmen\n",
      "sea\n",
      "searches\n",
      "secures\n",
      "seldom\n",
      "selfinterest\n",
      "selfsubsistent\n",
      "sending\n",
      "sensationthe\n",
      "sensedatabrown\n",
      "sensedatacolour\n",
      "sensedatafor\n",
      "sensedatawhich\n",
      "sensethoughts\n",
      "separated\n",
      "sequel\n",
      "serve\n",
      "service\n",
      "sets\n",
      "seventeenth\n",
      "severe\n",
      "shadow\n",
      "sharing\n",
      "sharp\n",
      "sheets\n",
      "shiny\n",
      "shock\n",
      "short\n",
      "shortly\n",
      "simplify\n",
      "situated\n",
      "skeleton\n",
      "sleeping\n",
      "slowly\n",
      "smelling\n",
      "smells\n",
      "sober\n",
      "society\n",
      "sold\n",
      "solicitation\n",
      "solid\n",
      "solve\n",
      "solves\n",
      "solving\n",
      "somebodys\n",
      "sophistry\n",
      "soul\n",
      "sour\n",
      "south\n",
      "spacerelations\n",
      "speakthat\n",
      "specially\n",
      "species\n",
      "spectacles\n",
      "speculative\n",
      "speech\n",
      "spoke\n",
      "spoons\n",
      "sprang\n",
      "staff\n",
      "stages\n",
      "started\n",
      "starting\n",
      "starts\n",
      "state’s\n",
      "step\n",
      "stone\n",
      "stored\n",
      "straightforward\n",
      "strangeness\n",
      "stranger\n",
      "strangest\n",
      "strike\n",
      "strikes\n",
      "striking\n",
      "strives\n",
      "striving\n",
      "struck\n",
      "structure\n",
      "struggling\n",
      "studies\n",
      "sublime\n",
      "subscribe\n",
      "subsequent\n",
      "subsequently\n",
      "subsumed\n",
      "subsumptions\n",
      "success\n",
      "successively\n",
      "suffering\n",
      "sufficed\n",
      "suggestion\n",
      "suggestions\n",
      "sumtotal\n",
      "suns\n",
      "sunset\n",
      "supplied\n",
      "suprasensible\n",
      "surprised\n",
      "surrender\n",
      "surrounded\n",
      "surveys\n",
      "survive\n",
      "surviving\n",
      "suspended\n",
      "swamp\n",
      "sweet\n",
      "synonymous\n",
      "systematize\n",
      "tableand\n",
      "tableare\n",
      "tablecloth\n",
      "tableit\n",
      "tableits\n",
      "tactile\n",
      "tap\n",
      "task\n",
      "tasting\n",
      "taught\n",
      "taxes\n",
      "telegram\n",
      "temper\n",
      "temperaments\n",
      "tempted\n",
      "tending\n",
      "tenet\n",
      "term\n",
      "texts\n",
      "texture\n",
      "theletters\n",
      "theoretical\n",
      "theses\n",
      "thesis\n",
      "thisthat\n",
      "thraldom\n",
      "throw\n",
      "throws\n",
      "thwarting\n",
      "timeless\n",
      "timerelations\n",
      "tincture\n",
      "tolerably\n",
      "tongue\n",
      "toothache\n",
      "topics\n",
      "total\n",
      "touches\n",
      "touchleaves\n",
      "trademarkcopyright\n",
      "traditional\n",
      "trains\n",
      "trammels\n",
      "transcribe\n",
      "transcription\n",
      "transfer\n",
      "transform\n",
      "transitory\n",
      "travels\n",
      "treated\n",
      "treating\n",
      "treatment\n",
      "trifling\n",
      "trotting\n",
      "trouble\n",
      "troubled\n",
      "troubles\n",
      "trusted\n",
      "tuning\n",
      "type\n",
      "types\n",
      "tyranny\n",
      "unaccustomed\n",
      "unaffected\n",
      "unattainable\n",
      "uncertain\n",
      "unchanged\n",
      "unchanging\n",
      "uncomfortable\n",
      "uncommon\n",
      "unconscious\n",
      "undeniable\n",
      "undeniably\n",
      "underlie\n",
      "underlies\n",
      "understandin\n",
      "undertake\n",
      "undiminished\n",
      "undue\n",
      "unenforceability\n",
      "unexpectedly\n",
      "unexperienced\n",
      "unimportant\n",
      "unites\n",
      "uniting\n",
      "unlearn\n",
      "unlink\n",
      "unnecessary1\n",
      "unplausible\n",
      "unprotected\n",
      "unpublished\n",
      "unreflectingly\n",
      "unreflective\n",
      "unsafe\n",
      "unsolicited\n",
      "unsolved\n",
      "unsound\n",
      "unsuspected\n",
      "unusual\n",
      "unwarrantable\n",
      "unwise\n",
      "updated\n",
      "upset\n",
      "upstairs\n",
      "urges\n",
      "usage\n",
      "vagueness\n",
      "vaguer\n",
      "vain\n",
      "valleys\n",
      "valueperhaps\n",
      "valuethrough\n",
      "variable\n",
      "variations\n",
      "variety\n",
      "variously\n",
      "varying\n",
      "vast\n",
      "veil\n",
      "verification\n",
      "version\n",
      "viewing\n",
      "viewwhich\n",
      "vindicate\n",
      "violates\n",
      "violent\n",
      "virtuous\n",
      "virus\n",
      "voice\n",
      "voices\n",
      "void\n",
      "volume\n",
      "volunteer\n",
      "voyage\n",
      "walk\n",
      "walks\n",
      "walled\n",
      "walls\n",
      "war\n",
      "warranties\n",
      "warrants\n",
      "waste\n",
      "wear\n",
      "wearing\n",
      "weather\n",
      "weight\n",
      "west\n",
      "window\n",
      "wise\n",
      "wissen\n",
      "wonderful\n",
      "wooden\n",
      "wore\n",
      "worst\n",
      "wrings\n",
      "writers\n",
      "wwwgutenbergorgcontact\n",
      "wwwgutenbergorglicense\n",
      "yield\n",
      "‘ASIS’\n",
      "“Defects”\n",
      "“Information\n",
      "“Right\n",
      "“the\n",
      "﻿The\n"
     ]
    }
   ],
   "source": [
    "#Finding out which is the least probable word and printing the words if there's a tie\n",
    "\n",
    "leastprobwords = []\n",
    "leastprob = float('inf')  \n",
    "\n",
    "with open(\"all_ns_words.csv\", \"r\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)  # Skip the header row\n",
    "\n",
    "    for row in csvreader:\n",
    "        word, _, probability = row\n",
    "        probability = float(probability)\n",
    "\n",
    "        if probability < leastprob:\n",
    "            leastprobwords = [word]\n",
    "            leastprob = probability\n",
    "        elif probability == leastprob:\n",
    "            leastprobwords.append(word)\n",
    "\n",
    "print(\"Least Probability is :\", leastprob)\n",
    "\n",
    "print(\"Least Probable Words are:\")\n",
    "for word in leastprobwords:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What observation can you make about the probabilities?\r",
    "## ANS :\n",
    "*  Diverse probability: The probability of the terms in the text collection are quite diverse. Some words have quite high probability, suggesting that they are often used and have a big impact on the organization and meaning of the text. A lot of terms, however, have extremely low probability, indicating that they are less common and could be more specialized or context-dependent\n",
    "* Importance of Rare Words: Words with low probability (around zero) are frequently less frequent and might include domain-specific phrases, technical jargon, or uncommon words. Despite being uncommon, certain words might be quite important for comprehending certain themes or settings in the text.\n",
    "* Normalization: Based on the overall frequency of non-stopwords, the word frequencies are normalized to get the probabilities. Regardless of the length of the text, this standardization makes comparing the significance of words easier. In the given text's context, words with greater probability are comparatively more significant.nt.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Probability for Sentence A: 0.008791536283713307\n",
      "Total Probability for Sentence B: 0.02309640888094174\n",
      "Sentence B is more likely.\n"
     ]
    }
   ],
   "source": [
    "# 4. Code to find out Which sentence is more likely: a. If a belief is true, it can be deduced it is universal. b. Criticism of knowledge is counter to scientific results.\n",
    "\n",
    "# Define the sentences\n",
    "sentence_a = \"If a belief is true, it can be deduced it is universal.\"\n",
    "sentence_b = \"Criticism of knowledge is counter to scientific results.\"\n",
    "\n",
    "# Create a dictionary to store word probabilities\n",
    "word_prob = {}\n",
    "\n",
    "# Open the all_ns_words.csv file and read word probabilities\n",
    "with open(\"all_ns_words.csv\", \"r\", newline=\"\", encoding=\"utf-8-sig\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)  \n",
    "    for row in csvreader:\n",
    "        word, _, prob = row\n",
    "        word_prob[word] = float(prob)\n",
    "\n",
    "# Function to calculate the total probability of a sentence\n",
    "def sentence_probability_calculation(sentence):\n",
    "    # Tokenize the sentence and calculate total probability\n",
    "    words = sentence.split()\n",
    "    total_prob = sum(word_prob.get(word.lower(), 0.0) for word in words)\n",
    "    return total_prob\n",
    "\n",
    "# Calculate the total probabilities for both sentences\n",
    "probabilityofa = sentence_probability_calculation(sentence_a)\n",
    "probabilityofb = sentence_probability_calculation(sentence_b)\n",
    "\n",
    "# Compare and print the results\n",
    "print(\"Total Probability for Sentence A:\", probabilityofa)\n",
    "print(\"Total Probability for Sentence B:\", probabilityofb)\n",
    "\n",
    "# Determine which sentence is more likely\n",
    "if probabilityofa > probabilityofb:\n",
    "    print(\"Sentence A is more likely.\")\n",
    "elif probabilityofb > probabilityofa:\n",
    "    print(\"Sentence B is more likely.\")\n",
    "else:\n",
    "    print(\"Both sentences have the same total probability.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": "1",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
